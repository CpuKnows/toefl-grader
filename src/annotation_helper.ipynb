{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tree import Tree\n",
    "# This uses corenlp server! Will need to alter code if using JAR files directly\n",
    "# https://stanfordnlp.github.io/CoreNLP/corenlp-server.html\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "from nltk.tag.stanford import CoreNLPTagger, CoreNLPPOSTagger, CoreNLPNERTagger\n",
    "\n",
    "# For spelling checker\n",
    "from enchant import Dict as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Careful! CoreNLPTagger, CoreNLPPOSTagger, and CoreNLPNERTagger will all be replaced in the next NLTK version (3.2.6)\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "#pos_tagger = CoreNLPPOSTagger(url='http://localhost:9000')\n",
    "#ner_tagger = CoreNLPNERTagger(url='http://localhost:9000')\n",
    "pos_tagger = CoreNLPTagger(tagtype='pos', url='http://localhost:9000')\n",
    "ner_tagger = CoreNLPTagger(tagtype='ner', url='http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get essays\n",
    "essay_key = pd.read_csv('../data/essays_dataset/index.csv', sep=';')\n",
    "\n",
    "essays = []\n",
    "for filename in essay_key['filename']:\n",
    "    with open('../data/essays_dataset/essays/'+filename, 'r') as f:\n",
    "        essays.append(f.read().strip())\n",
    "        \n",
    "essay_key['essay'] = essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>grade</th>\n",
       "      <th>word_len</th>\n",
       "      <th>grader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>990384.txt</td>\n",
       "      <td>high</td>\n",
       "      <td>568</td>\n",
       "      <td>Aldo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395987.txt</td>\n",
       "      <td>high</td>\n",
       "      <td>508</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949465.txt</td>\n",
       "      <td>high</td>\n",
       "      <td>458</td>\n",
       "      <td>Aldo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38209.txt</td>\n",
       "      <td>high</td>\n",
       "      <td>456</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1834502.txt</td>\n",
       "      <td>high</td>\n",
       "      <td>454</td>\n",
       "      <td>Aldo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename grade  word_len grader\n",
       "0   990384.txt  high       568   Aldo\n",
       "1   395987.txt  high       508   John\n",
       "2  1949465.txt  high       458   Aldo\n",
       "3    38209.txt  high       456   John\n",
       "4  1834502.txt  high       454   Aldo"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_split = pd.read_csv('../data/essays_dataset/essay_split.csv')\n",
    "essay_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altered behavior of NLTK so CoreNLP performs sentence splits\n",
    "def constituency_parse(parser, sentences, return_parse_obj=False):\n",
    "    \"\"\"Creates parse strings for each sentence.  \n",
    "    Each parse string can be fed into Tree.fromstring() to create NLTK Tree objects.\n",
    "\n",
    "    parser (CoreNLPParser): parser to parse sentences\n",
    "    sentences (str): essay text\n",
    "    return_parse_obj (bool): return parse object or string of trees\n",
    "    RETURNS (list): a list of parses in string form\n",
    "    \"\"\"\n",
    "    default_properties = {'outputFormat': 'json', \n",
    "                          'annotators': 'tokenize,pos,lemma,ssplit,parse'}\n",
    "    parsed_data = parser.api_call(sentences, properties=default_properties)\n",
    "    if return_parse_obj:\n",
    "        return parsed_data\n",
    "    else:\n",
    "        parses = list()\n",
    "        for parsed_sent in parsed_data['sentences']:\n",
    "            parse = parsed_sent['parse']\n",
    "            # Compress whitespace\n",
    "            parse = re.sub('[\\s]+', ' ', parse)\n",
    "            parses.append(parse)\n",
    "        return parses\n",
    "\n",
    "def pos_tags(tagger, sentences):\n",
    "    \"\"\"Tags sentences with POS tags. Returns a list of (word, tag, start index, end index) tuples\n",
    "\n",
    "    tagger (CoreNLPTagger): a tagger to tag sentences\n",
    "    RETURNS (list): list of (word, tag) tuples\n",
    "    \"\"\"\n",
    "    default_properties = {'annotators': 'tokenize,ssplit,pos'}\n",
    "    tagged_data = tagger.api_call(sentences, properties=default_properties)\n",
    "    \n",
    "    tags = list()\n",
    "    for sent in tagged_data['sentences']:\n",
    "        tags.append([(token['word'], token['pos'], token['characterOffsetBegin'], token['characterOffsetEnd']) for token in sent['tokens']])\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_str(trees):\n",
    "    \"\"\"Joins a list of trees in string form\"\"\"\n",
    "    return ' '.join(trees)\n",
    "\n",
    "def str_to_trees(tree_str):\n",
    "    \"\"\"Splits a string into a list of trees in string form\"\"\"\n",
    "    d = \"(ROOT\"\n",
    "    return  [(d+sent).strip() for sent in tree_str.split(d) if sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_sentence_annotation(parsed_data, orig_text, verbose=True):\n",
    "    sentences = dict()\n",
    "    sentences['indices'] = list()\n",
    "    \n",
    "    if verbose:\n",
    "        print('Format: (Start index, end index) Sentence')\n",
    "        print()\n",
    "        \n",
    "    for sent in parsed_data['sentences']:\n",
    "        start_offset = sent['tokens'][0]['characterOffsetBegin']\n",
    "        end_offset = sent['tokens'][-1]['characterOffsetEnd']\n",
    "        sentences['indices'].append((start_offset, end_offset))\n",
    "        if verbose:\n",
    "            print((start_offset, end_offset), orig_text[start_offset:end_offset])\n",
    "            print()\n",
    "        \n",
    "    sentences['num'] = len(parsed_data['sentences'])\n",
    "    if verbose:\n",
    "        print('Num sentence:', len(parsed_data['sentences']))\n",
    "        print()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_sanity_check(sentence_dict):\n",
    "    error = False\n",
    "    \n",
    "    if sentence_dict['num'] != len(sentence_dict['indices']):\n",
    "        print('Number of sentences does not match')\n",
    "        error = True\n",
    "        \n",
    "    prev = 0\n",
    "    for i,j in enumerate(sentence_dict['indices']):\n",
    "        if j[0] >= j[1]:\n",
    "            print('Sentence', i, ': Start/end indices overlap')\n",
    "            error = True\n",
    "        if prev >= j[0] and prev != 0:\n",
    "            print('Sentence', i, ': Previous end index overlaps start index')\n",
    "            error = True\n",
    "        if j[0] - prev > 1:\n",
    "            print('Sentence', i, ': Is gap between sentences > 1 character/space?')\n",
    "            error = True\n",
    "        prev = j[1]\n",
    "    \n",
    "    if not error:\n",
    "        print('No errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word(orig_text, word):\n",
    "    matches = list()\n",
    "    for m in re.finditer(word, orig_text, flags=re.I):\n",
    "        #print(m)\n",
    "        if m.span(0)[0] < 10:\n",
    "            before_context = (' ' * (10-m.span(0)[0])) + orig_text[0:m.span(0)[0]]\n",
    "        else:\n",
    "            before_context = orig_text[m.span(0)[0]-10 : m.span(0)[0]]\n",
    "        \n",
    "        if len(orig_text) - m.span(0)[1] < 10:\n",
    "            #print(orig_text[m.span(0)[1]:])\n",
    "            #print(' ' * (len(orig_text) - m.span(0)[1]))\n",
    "            after_context = orig_text[m.span(0)[1]:] + (' ' * (len(orig_text) - m.span(0)[1]))\n",
    "        else:\n",
    "            after_context = orig_text[m.span(0)[1] : m.span(0)[1]+10]\n",
    "            \n",
    "        matches.append((m.span(0), '...' + before_context + orig_text[m.span(0)[0]:m.span(0)[1]] + after_context + '...'))\n",
    "        \n",
    "    if len(matches) == 1:\n",
    "        return matches[0][0]\n",
    "    else:\n",
    "        for i,m in enumerate(matches):\n",
    "            print('Index:', i, '-', m)\n",
    "            \n",
    "        choice = int(input('Choose a match index (number) or -1 for all: '))\n",
    "        if choice == -1:\n",
    "            return [m[0] for m in matches]\n",
    "        else:\n",
    "            return matches[choice][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spelling(dictionary, parsed_sentences, origin_text,verbose=True):\n",
    "    \"\"\"Check the spelling of tagged words on an essay\n",
    "    and return the list of misspelling words with their tags \n",
    "    and indexes of begining and end of those words\"\"\"\n",
    "    wrong_words = dict()\n",
    "    wrong_words['indices'] = list()\n",
    "    \n",
    "    if verbose:\n",
    "        print('Format: (Start index, end index) word')\n",
    "        print()\n",
    "        \n",
    "    for sentence in parsed_sentences:\n",
    "        for w_tuple in sentence:\n",
    "            word = w_tuple[0]\n",
    "            if(word !=',' and word != \"'s\"):\n",
    "                if dicc.check(word) is False:\n",
    "                    tag = w_tuple[1]\n",
    "                    start_offset = w_tuple[2]\n",
    "                    end_offset = w_tuple[3]\n",
    "                    wrong_words['indices'].append((word, tag, start_offset, end_offset))\n",
    "                    if verbose:\n",
    "                        print((start_offset, end_offset), orig_text[start_offset:end_offset])\n",
    "                        print()\n",
    "    wrong_words['num'] = len(wrong_words['indices'])\n",
    "    if verbose:\n",
    "        print('Num wrong words:', len(wrong_words['indices']))\n",
    "        print()\n",
    "    return wrong_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_filename = essay_key.loc[0,'filename']\n",
    "orig_text = essay_key.loc[0,'essay']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essay length in sentences\n",
    "num_sentence_annotation() automatically parses the sentence and returns a dictionary.  \n",
    "If you disagree with the parse then edit the dictionary object so it's correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an important aspect of today time.\n",
      "This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n",
      "Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n",
      "To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n",
      "More people go to this program television to talk about your problem, that is very radicate in my nation.\n",
      "The modern society rappresented the perfect ambient to influenced the minds of all the person.\n",
      "In my self is present the reasons of this statement, that is one of the problem of the life.\n",
      "But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n",
      "Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n",
      "But to explain all the aspect about this argoment is very inportant to illustre any examples.\n",
      "The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n",
      "This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n",
      "The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n",
      "The my request is that the new politics discuss about this problem.\n"
     ]
    }
   ],
   "source": [
    "print(orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format: (Start index, end index) Sentence\n",
      "\n",
      "(0, 42) This is an important aspect of today time.\n",
      "\n",
      "(43, 236) This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n",
      "\n",
      "(237, 359) Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n",
      "\n",
      "(360, 487) To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n",
      "\n",
      "(488, 593) More people go to this program television to talk about your problem, that is very radicate in my nation.\n",
      "\n",
      "(594, 688) The modern society rappresented the perfect ambient to influenced the minds of all the person.\n",
      "\n",
      "(689, 781) In my self is present the reasons of this statement, that is one of the problem of the life.\n",
      "\n",
      "(782, 918) But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n",
      "\n",
      "(919, 1053) Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n",
      "\n",
      "(1054, 1147) But to explain all the aspect about this argoment is very inportant to illustre any examples.\n",
      "\n",
      "(1148, 1302) The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n",
      "\n",
      "(1303, 1450) This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n",
      "\n",
      "(1451, 1634) The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n",
      "\n",
      "(1635, 1702) The my request is that the new politics discuss about this problem.\n",
      "\n",
      "Num sentence: 14\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"num\": 14, \"indices\": [[0, 42], [43, 236], [237, 359], [360, 487], [488, 593], [594, 688], [689, 781], [782, 918], [919, 1053], [1054, 1147], [1148, 1302], [1303, 1450], [1451, 1634], [1635, 1702]]}'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = num_sentence_annotation(constituency_parse(parser, orig_text, return_parse_obj=True), orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors\n"
     ]
    }
   ],
   "source": [
    "sentence_sanity_check(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_num_sentences = output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling mistakes\n",
    "Create ONE list of all misspelled word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an important aspect of today time.\n",
      "This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n",
      "Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n",
      "To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n",
      "More people go to this program television to talk about your problem, that is very radicate in my nation.\n",
      "The modern society rappresented the perfect ambient to influenced the minds of all the person.\n",
      "In my self is present the reasons of this statement, that is one of the problem of the life.\n",
      "But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n",
      "Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n",
      "But to explain all the aspect about this argoment is very inportant to illustre any examples.\n",
      "The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n",
      "This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n",
      "The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n",
      "The my request is that the new politics discuss about this problem.\n"
     ]
    }
   ],
   "source": [
    "print(orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format: (Start index, end index) word\n",
      "\n",
      "(57, 63) rathen\n",
      "\n",
      "(187, 199) rappresented\n",
      "\n",
      "(288, 300) rappresented\n",
      "\n",
      "(376, 384) argoment\n",
      "\n",
      "(466, 478) rappresented\n",
      "\n",
      "(571, 579) radicate\n",
      "\n",
      "(613, 625) rappresented\n",
      "\n",
      "(1009, 1021) rappresented\n",
      "\n",
      "(1095, 1103) argoment\n",
      "\n",
      "(1112, 1121) inportant\n",
      "\n",
      "(1125, 1133) illustre\n",
      "\n",
      "(1215, 1223) argoment\n",
      "\n",
      "(1316, 1328) rappresented\n",
      "\n",
      "(1505, 1515) rappresent\n",
      "\n",
      "(1525, 1533) argoment\n",
      "\n",
      "(1625, 1633) argoment\n",
      "\n",
      "Num wrong words: 16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dicc = dictionary(\"en_US\")\n",
    "output = check_spelling(dicc, pos_tags(pos_tagger, orig_text), orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - ((187, 199), '...lient not rappresented the impor...')\n",
      "Index: 1 - ((288, 300), '...at is not rappresented the your ...')\n",
      "Index: 2 - ((466, 478), '...e problem rappresented by this.\\n...')\n",
      "Index: 3 - ((613, 625), '...n society rappresented the perfe...')\n",
      "Index: 4 - ((1009, 1021), '... day, and rappresented the probl...')\n",
      "Index: 5 - ((1316, 1328), '...s opinion rappresented my self i...')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(187, 199), (288, 300), (466, 478), (613, 625), (1009, 1021), (1316, 1328)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word(orig_text, 'rappresented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final errors\n",
    "errors_spelling = [(187, 199), (288, 300), (466, 478), (613, 625), (1009, 1021), (1316, 1328), (), ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject Verb Disagreement\n",
    "Create ONE list of all disagreeing word indices.  \n",
    "Choose one word of the 2 words to be the one disagreeing.  \n",
    "Not completely sure about how to identify which word is at fault. Try identifying based on sentence / essay context for the purpose of annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an important aspect of today time.\n",
      "This products rathen are not much better, but today is not important the really character of the product, but only the money and the client not rappresented the important actor in this process.\n",
      "Every day any people buy same products that is not rappresented the your necessity, but is only important buy any product.\n",
      "To explain this argoment in my nation, at the television, there is an program that discuss of the problem rappresented by this.\n",
      "More people go to this program television to talk about your problem, that is very radicate in my nation.\n",
      "The modern society rappresented the perfect ambient to influenced the minds of all the person.\n",
      "In my self is present the reasons of this statement, that is one of the problem of the life.\n",
      "But not all the people and the time is in accord with this problem, because any time the person is too according with the make products.\n",
      "Thus I agree with this statement, because this event is present in my life every day, and rappresented the problem with I do fighting.\n",
      "But to explain all the aspect about this argoment is very inportant to illustre any examples.\n",
      "The television programs that every day introduce in the minds more argoment, news and other problem, or breaking news, is the first actor in this process.\n",
      "This opinion rappresented my self in my life, because for me the life of all the people is not possible to influence by the activity of any person.\n",
      "The society lose the propriety when this problem will rappresent the must argoment of the talk and the life of the people, because as very difficult live at a time with this argoment.\n",
      "The my request is that the new politics discuss about this problem.\n"
     ]
    }
   ],
   "source": [
    "orig_text = essay_key.loc[0,'essay']\n",
    "print(orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - ((187, 199), '...lient not rappresented the impor...')\n",
      "Index: 1 - ((288, 300), '...at is not rappresented the your ...')\n",
      "Index: 2 - ((466, 478), '...e problem rappresented by this.\\n...')\n",
      "Index: 3 - ((613, 625), '...n society rappresented the perfe...')\n",
      "Index: 4 - ((1009, 1021), '... day, and rappresented the probl...')\n",
      "Index: 5 - ((1316, 1328), '...s opinion rappresented my self i...')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(187, 199)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word(orig_text, 'rappresented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final errors\n",
    "errors_subj_verb = [(187, 199), (), ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verb tense / missing verb\n",
    "Create ONE list of all word indices with the type of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - ((187, 199), '...lient not rappresented the impor...')\n",
      "Index: 1 - ((288, 300), '...at is not rappresented the your ...')\n",
      "Index: 2 - ((466, 478), '...e problem rappresented by this.\\n...')\n",
      "Index: 3 - ((613, 625), '...n society rappresented the perfe...')\n",
      "Index: 4 - ((1009, 1021), '... day, and rappresented the probl...')\n",
      "Index: 5 - ((1316, 1328), '...s opinion rappresented my self i...')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(187, 199)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word(orig_text, 'rappresented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final errors\n",
    "errors_verb = [{'offset': (187, 199), 'type': 'verb tense'}, {}, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous\n",
    "Create ONE list of all indices with the type of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0 - ((31, 36), '...aspect of today time.\\nThi...')\n",
      "Index: 1 - ((89, 94), '...tter, but today is not im...')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31, 36)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_word(orig_text, 'today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_misc = [{'offset': 36, 'type': 'missing possessive'}, {}, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine results and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>errors</th>\n",
       "      <th>length_score</th>\n",
       "      <th>spelling_score</th>\n",
       "      <th>subj_verb_score</th>\n",
       "      <th>verb_score</th>\n",
       "      <th>sentence_formation_score</th>\n",
       "      <th>semantic_coherent_score</th>\n",
       "      <th>semantic_topic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004355.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1007363.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1079196.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1086343.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1096747.txt</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename errors  length_score  spelling_score  subj_verb_score  \\\n",
       "0  1004355.txt                  NaN             NaN              NaN   \n",
       "1  1007363.txt                  NaN             NaN              NaN   \n",
       "2  1079196.txt                  NaN             NaN              NaN   \n",
       "3  1086343.txt                  NaN             NaN              NaN   \n",
       "4  1096747.txt                  NaN             NaN              NaN   \n",
       "\n",
       "   verb_score  sentence_formation_score  semantic_coherent_score  \\\n",
       "0         NaN                       NaN                      NaN   \n",
       "1         NaN                       NaN                      NaN   \n",
       "2         NaN                       NaN                      NaN   \n",
       "3         NaN                       NaN                      NaN   \n",
       "4         NaN                       NaN                      NaN   \n",
       "\n",
       "   semantic_topic_score  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_errors = pd.DataFrame({'filename': essay_key['filename'].tolist()})\n",
    "essay_errors['errors'] = ''\n",
    "essay_errors['length_score'] = np.nan\n",
    "essay_errors['spelling_score'] = np.nan\n",
    "essay_errors['subj_verb_score'] = np.nan\n",
    "essay_errors['verb_score'] = np.nan\n",
    "essay_errors['sentence_formation_score'] = np.nan\n",
    "essay_errors['semantic_coherent_score'] = np.nan\n",
    "essay_errors['semantic_topic_score'] = np.nan\n",
    "essay_errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = {'num sentences': errors_num_sentences,\n",
    "          'subj verb': errors_subj_verb, \n",
    "          'verb': errors_verb, \n",
    "          'misc': errors_misc}\n",
    "errors = json.dump(errors)\n",
    "\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'errors'] = errors\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'length_score'] = 0\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'spelling_score'] = 4\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'subj_verb_score'] = 0\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'verb_score'] = 0\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'sentence_formation_score'] = 0\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'semantic_coherent_score'] = 0\n",
    "essay_errors.loc[lambda df: df['filename'] == orig_filename, 'semantic_topic_score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_errors.to_csv('../data/essay_dataset/essay_errors_john.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
